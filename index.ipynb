{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Mean Absolute Error = 7.745559243921434\n",
      "Decision Tree: Mean Absolute Error = 4.241626213592233\n",
      "Support Vector Machine: Mean Absolute Error = 7.51494696620429\n",
      "Random Forest: Mean Absolute Error = 3.7794801982200665\n",
      "XGBoost: Mean Absolute Error = 2.996374957538346\n",
      "AdaBoost: Mean Absolute Error = 6.415728567746745\n",
      "Gradient Boosting: Mean Absolute Error = 4.138748889593647\n",
      "KNN: Mean Absolute Error = 6.800514563106796\n",
      "ANN: Mean Absolute Error = 9.02367941260824\n",
      "Ridge Regression: Mean Absolute Error = 7.751966725393744\n",
      "Lasso Regression: Mean Absolute Error = 8.716246800286958\n",
      "Elastic Net Regression: Mean Absolute Error = 9.232295635942508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"concrete_data.csv\")\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=['concrete_compressive_strength'])\n",
    "y = df['concrete_compressive_strength']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate all models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"ANN\": MLPRegressor(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Elastic Net Regression\": ElasticNet()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    print(f\"{name}: Mean Absolute Error = {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 2000}\n",
      "Mean Absolute Error: 2.796709563153461\n",
      "XGBoost - Mean Squared Error: 17.234885287026657\n",
      "XGBoost - Training R^2 Score: 0.9936956586664092\n",
      "XGBoost - Test R^2 Score: 0.93311435497694\n",
      "MSE: 17.234885287026657\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [3, 5, 6],\n",
    "    'learning_rate': [0.3, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions on the test data\n",
    "best_xgb = grid_search.best_estimator_\n",
    "predictions = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the mean absolute error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"XGBoost - Mean Squared Error:\", mse)\n",
    "\n",
    "# Fit the best XGBoost estimator to the training data\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calculate and print the R^2 score on the training and test data\n",
    "train_score = best_xgb.score(X_train_scaled, y_train)\n",
    "test_score = best_xgb.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"XGBoost - Training R^2 Score:\", train_score)\n",
    "print(\"XGBoost - Test R^2 Score:\", test_score)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "\n",
    "print('MSE:', mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 1000}\n",
    "Mean Absolute Error: 2.756640979896471\n",
    "\n",
    "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 2000}\n",
    "Mean Absolute Error: 2.796709563153461\n",
    "XGBoost - Mean Squared Error: 17.234885287026657\n",
    "XGBoost - Training R^2 Score: 0.9936956586664092\n",
    "XGBoost - Test R^2 Score: 0.93311435497694\n",
    "Accuracy DT: 0.93311435497694\n",
    "MSE: 17.234885287026657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 2000}\n",
      "Mean Absolute Error: 2.796709563153461\n",
      "XGBoost - Mean Squared Error: 17.234885287026657\n",
      "XGBoost - Training R^2 Score: 0.9936956586664092\n",
      "XGBoost - Test R^2 Score: 0.93311435497694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from joblib import dump\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"concrete_data.csv\")\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=['concrete_compressive_strength'])\n",
    "y = df['concrete_compressive_strength']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [3, 5, 6],\n",
    "    'learning_rate': [0.3, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions on the test data\n",
    "best_xgb = grid_search.best_estimator_\n",
    "predictions = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the mean absolute error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Calculate and print the mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"XGBoost - Mean Squared Error:\", mse)\n",
    "\n",
    "# Fit the best XGBoost estimator to the training data\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calculate and print the R^2 score on the training and test data\n",
    "train_score = best_xgb.score(X_train_scaled, y_train)\n",
    "test_score = best_xgb.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"XGBoost - Training R^2 Score:\", train_score)\n",
    "print(\"XGBoost - Test R^2 Score:\", test_score)\n",
    "\n",
    "# Save the trained model to a .pkl file\n",
    "dump(best_xgb, 'model.pkl')\n",
    "\n",
    "# Save the scaler\n",
    "dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>158.6</td>\n",
       "      <td>148.9</td>\n",
       "      <td>116.0</td>\n",
       "      <td>175.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>953.3</td>\n",
       "      <td>719.7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>424.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>822.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>275.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.4</td>\n",
       "      <td>159.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1053.6</td>\n",
       "      <td>777.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>252.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>168.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>124.3</td>\n",
       "      <td>158.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1080.8</td>\n",
       "      <td>796.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>286.3</td>\n",
       "      <td>200.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>803.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>246.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.1</td>\n",
       "      <td>143.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1086.8</td>\n",
       "      <td>800.9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>190.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>166.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>798.9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>475.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>852.1</td>\n",
       "      <td>781.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "995   158.6               148.9    116.0  175.1              15.0   \n",
       "507   424.0                22.0    132.0  178.0               8.5   \n",
       "334   275.1                 0.0    121.4  159.5               9.9   \n",
       "848   252.0                97.0     76.0  194.0               8.0   \n",
       "294   168.9                42.2    124.3  158.3              10.8   \n",
       "..      ...                 ...      ...    ...               ...   \n",
       "87    286.3               200.9      0.0  144.7              11.2   \n",
       "330   246.8                 0.0    125.1  143.3              12.0   \n",
       "466   190.3                 0.0    125.2  166.6               9.9   \n",
       "121   475.0               118.8      0.0  181.1               8.9   \n",
       "860   314.0                 0.0    113.0  170.0              10.0   \n",
       "\n",
       "     coarse_aggregate  fine_aggregate   age  \n",
       "995             953.3            719.7   28  \n",
       "507             822.0            750.0   28  \n",
       "334            1053.6            777.5    3  \n",
       "848             835.0            821.0   28  \n",
       "294            1080.8            796.2    3  \n",
       "..                ...              ...  ...  \n",
       "87             1004.6            803.7    3  \n",
       "330            1086.8            800.9   14  \n",
       "466            1079.0            798.9  100  \n",
       "121             852.1            781.5   28  \n",
       "860             925.0            783.0   28  \n",
       "\n",
       "[824 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
      "995   158.6               148.9    116.0  175.1              15.0   \n",
      "507   424.0                22.0    132.0  178.0               8.5   \n",
      "334   275.1                 0.0    121.4  159.5               9.9   \n",
      "848   252.0                97.0     76.0  194.0               8.0   \n",
      "294   168.9                42.2    124.3  158.3              10.8   \n",
      "\n",
      "     coarse_aggregate  fine_aggregate   age  \n",
      "995             953.3            719.7   28  \n",
      "507             822.0            750.0   28  \n",
      "334            1053.6            777.5    3  \n",
      "848             835.0            821.0   28  \n",
      "294            1080.8            796.2    3  \n",
      "Number of features in X_train: 8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(\"Number of features in X_train:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- fine_aggregate\nFeature names seen at fit time, yet now missing:\n- fine_aggregate \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m input_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(input_data)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Scale the input data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m input_df_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions using the trained XGBoost model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m predictions \u001b[38;5;241m=\u001b[39m best_xgb\u001b[38;5;241m.\u001b[39mpredict(input_df_scaled)\n",
      "File \u001b[1;32mc:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- fine_aggregate\nFeature names seen at fit time, yet now missing:\n- fine_aggregate \n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    'cement': [350, 400, 450, 500, 550, 300, 380, 420, 470, 510],\n",
    "    'blast_furnace_slag': [0, 20, 40, 60, 80, 100, 120, 140, 160, 180],\n",
    "    'fly_ash': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
    "    'water': [150, 160, 170, 180, 190, 200, 210, 220, 230, 240],\n",
    "    'superplasticizer': [0, 5, 10, 15, 20, 25, 30, 35, 40, 45],\n",
    "    'coarse_aggregate': [1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450],\n",
    "    'fine_aggregate': [700, 720, 740, 760, 780, 800, 820, 840, 860, 880],\n",
    "    'age': [28, 28, 28, 28, 28, 28, 28, 28, 28, 28]\n",
    "}\n",
    "\n",
    "# Convert input data into a DataFrame\n",
    "input_df = pd.DataFrame(input_data)\n",
    "\n",
    "# Scale the input data\n",
    "input_df_scaled = scaler.transform(input_df)\n",
    "\n",
    "# Make predictions using the trained XGBoost model\n",
    "predictions = best_xgb.predict(input_df_scaled)\n",
    "\n",
    "# Print predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Prediction for input {i+1}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names used during training: ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate ', 'age']\n",
      "Prediction for input 1: 50.67439651489258\n",
      "Prediction for input 2: 51.64189529418945\n",
      "Prediction for input 3: 45.82851028442383\n",
      "Prediction for input 4: 68.34516143798828\n",
      "Prediction for input 5: 63.9072380065918\n",
      "Prediction for input 6: 38.337215423583984\n",
      "Prediction for input 7: 43.74569320678711\n",
      "Prediction for input 8: 40.13999938964844\n",
      "Prediction for input 9: 60.53358459472656\n",
      "Prediction for input 10: 66.7478256225586\n"
     ]
    }
   ],
   "source": [
    "# Check the feature names used during training\n",
    "print(\"Feature names used during training:\", X_train.columns.tolist())\n",
    "\n",
    "# Ensure that the input DataFrame for prediction has the same column names in the same order\n",
    "input_df = pd.DataFrame(input_data, columns=X_train.columns)\n",
    "\n",
    "# Scale the input data\n",
    "input_df_scaled = scaler.transform(input_df)\n",
    "\n",
    "# Make predictions using the trained XGBoost model\n",
    "predictions = best_xgb.predict(input_df_scaled)\n",
    "\n",
    "# Print predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Prediction for input {i+1}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (Response Time): 0.011525869369506836 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions\n",
    "prediction = best_xgb.predict(X_train_scaled)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate latency\n",
    "latency = end_time - start_time\n",
    "print(\"Latency (Response Time):\", latency, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 2000}\n",
      "Mean Absolute Error: 2.796709563153461\n",
      "XGBoost - Mean Squared Error: 17.234885287026657\n",
      "XGBoost - Training R^2 Score: 0.9936956586664092\n",
      "XGBoost - Test R^2 Score: 0.93311435497694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from joblib import dump\n",
    "import mlflow\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"concrete_data.csv\")\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=['concrete_compressive_strength'])\n",
    "y = df['concrete_compressive_strength']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [3, 5, 6],\n",
    "    'learning_rate': [0.3, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions on the test data\n",
    "best_xgb = grid_search.best_estimator_\n",
    "predictions = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the mean absolute error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Calculate and print the mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"XGBoost - Mean Squared Error:\", mse)\n",
    "\n",
    "# Fit the best XGBoost estimator to the training data\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calculate and print the R^2 score on the training and test data\n",
    "train_score = best_xgb.score(X_train_scaled, y_train)\n",
    "test_score = best_xgb.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"XGBoost - Training R^2 Score:\", train_score)\n",
    "print(\"XGBoost - Test R^2 Score:\", test_score)\n",
    "\n",
    "# Log metrics with MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"Training_R2_Score\", train_score)\n",
    "    mlflow.log_metric(\"Test_R2_Score\", test_score)\n",
    "\n",
    "    # Save the trained model to a .pkl file\n",
    "    dump(best_xgb, 'model.pkl')\n",
    "\n",
    "    # Save the scaler\n",
    "    dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
